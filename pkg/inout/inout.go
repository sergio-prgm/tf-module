// Package inout contains functions that deal with io
// operations, reading and writing the contents of the
// files generated by [scf]
package inout

import (
	"encoding/csv"
	"fmt"
	"io/ioutil"
	"log"
	"os"
	"path/filepath"
	"strings"

	"github.com/buger/jsonparser"
	"github.com/sergio-prgm/tf-module/pkg/util"
	"gopkg.in/yaml.v3"
)

type Modules struct {
	Name      string   `yaml:"name"`
	Resources []string `yaml:"resources"`
}

type YamlMapping struct {
	Modules []Modules `yaml:"modules"`
	Confg   []string  `yaml:"config"`
}

type ParsedTf struct {
	Providers []string
	Resources []string
}

type Resource struct {
	ResourceID   string `json:"resource_id"`
	ResourceType string `json:"resource_type"`
	ResourceName string `json:"resource_name"`
}

type ModuleResource struct {
	Module       string
	ResourceType string
	Quantity     string
}

type CsvResources struct {
	Resource string `json:"Resource"`
	Module   string `json:"Module"`
	Quantity int    `json:"Quantity"`
}

type BlockInnerKey struct {
	MainKey        string `json:"MainKey"`
	InnerKey       string `json:"InnerKey"`
	SecondInnerKey string `json:"SecondInnerKey"`
	Line           string `json:"Line"`
}

// ReadConfig creates a structured YamlMapping
// to use in tfvars, variables, modules, etc.
func ReadConfig(fileName string) YamlMapping {
	filePath := fmt.Sprintf("%s/tfmodule.yaml", strings.TrimSuffix(fileName, "/"))
	conf, err := os.ReadFile(filePath)

	if err != nil {
		log.Fatalf("ERROR: %s doesn't exist", filePath)
	} else {
		fmt.Printf("Reading modules from %s\n", util.EmphasizeStr(filePath, util.Yellow, util.Normal))
	}

	return ParseConfig(conf)
}

// ParseConfig
// parses the contents of the provided yaml file into a YamlMapping structure
func ParseConfig(conf []byte) YamlMapping {
	configModules := YamlMapping{}
	err := yaml.Unmarshal(conf, &configModules)

	if err != nil {
		log.Fatal()
	}
	return configModules
}

// ParseConfig
// read the contents of the tf files and parses into a ParsedTf structure
func ReadTfFiles(fileName string) ParsedTf {
	tfFile := fmt.Sprintf("%s/main.tf", strings.TrimSuffix(fileName, "/"))
	tfFiles, err := os.ReadDir(strings.TrimSuffix(fileName, "/"))
	allTf := []byte("")

	for i := len(tfFiles) - 1; i >= 0; i-- {
		v := tfFiles[i]
		if strings.HasSuffix(v.Name(), ".tf") {
			fmt.Println(v.Name())
			currentTfFile, err := os.ReadFile(fileName + v.Name())
			if err != nil {
				log.Fatal(err)
			}
			allTf = append(allTf, currentTfFile...)
		}
	}

	if err != nil {
		log.Fatalf("ERROR: %s doesn't exist", tfFile)
	} else {
		fmt.Printf("Reading terraform main from %s\n", util.EmphasizeStr(tfFile, util.Yellow, util.Normal))
	}

	return ReadTf(allTf)
}

// ReadTf
// parses the contents provided of the raw []byte and returns a structure of ParsedTf with the providers and resources
func ReadTf(raw []byte) ParsedTf {
	file := string(raw[:])
	fileLines := strings.Split(file, "\n")

	isProv := false
	isResource := false
	isBlock := false
	isDependsOn := false

	var rawProv []string
	var rawResource []string

	var currentBlock string

	for i := 0; i < len(fileLines); i++ {

		if !isBlock {

			firstWord := strings.Split(fileLines[i], " ")[0]

			if firstWord == "resource" {
				// fmt.Print("\nStart of resource\n")
				isResource = true
				isBlock = true
			} else if firstWord == "terraform" || firstWord == "provider" {
				// fmt.Print("\nStart of provider/tf\n")
				isBlock = true
				isProv = true
			} else {
				currentBlock = ""
				isBlock = false
			}
		}
		if fileLines[i] == "}" && isBlock {
			if isResource {
				currentBlock += fileLines[i]
				rawResource = append(rawResource, currentBlock)
				isResource = false
				isBlock = false
				currentBlock = ""
			} else if isProv {
				currentBlock += fileLines[i]
				rawProv = append(rawProv, currentBlock)
				isProv = false
				isBlock = false
				currentBlock = ""
			}
		}
		if isBlock {
			if !isDependsOn {
				// if util.FirstWordIs(fileLines[i])
				firstWordInside := strings.Split(strings.TrimSpace(fileLines[i]), " ")[0]

				if firstWordInside == "depends_on" {
					isDependsOn = true
				} else {
					currentBlock += fileLines[i] + "\n"
				}
			} else {
				firstWordInside := strings.Split(strings.TrimSpace(fileLines[i]), " ")[0]
				if firstWordInside == "]" {
					isDependsOn = false
				}
			}
		}

	}
	return ParsedTf{
		Resources: rawResource,
		Providers: rawProv,
	}
}

// JsonParser
// read the json file provided and parse each resource into an array of structured Resource
func JsonParser(fileName string) []Resource {
	fileContent, err := ioutil.ReadFile(fileName)
	if err != nil {
		log.Fatalf("Failed reading the file: %s", err)
	}

	var resources []Resource

	jsonparser.ObjectEach(fileContent, func(key []byte, value []byte, dataType jsonparser.ValueType, offset int) error {
		var res Resource
		jsonparser.ObjectEach(value, func(innerKey []byte, innerValue []byte, innerDataType jsonparser.ValueType, innerOffset int) error {
			switch strings.ToLower(string(innerKey)) {
			case "resource_id":
				res.ResourceID = string(innerValue)
			case "resource_type":
				res.ResourceType = string(innerValue)
			case "resource_name":
				res.ResourceName = string(innerValue)
			}
			return nil
		})
		resources = append(resources, res)
		return nil
	})

	return resources
}

// ParseCSV
// read the csv file provided and parse each resource with is module into an array of structured ModuleResource
func ParseCSV(filename string) []ModuleResource {
	file, err := os.Open(filename)
	if err != nil {
		log.Fatalf("Error: csv file does not exist: %s", err)
	}
	defer file.Close()

	r := csv.NewReader(file)

	// Read and discard header
	_, err = r.Read()
	if err != nil {
		log.Fatalf("Error reading the csv file: %s", err)
	}

	rows, err := r.ReadAll()
	if err != nil {
		log.Fatalf("Error reading the csv file: %s", err)
	}

	var resources []ModuleResource
	for _, row := range rows {
		if len(row) < 2 {
			// Skip rows with fewer than 2 fields or handle the error accordingly
			fmt.Printf("Warning: encountered a row with fewer than 2 fields: %v. Skipping.\n", row)
			continue
		}
		resources = append(resources, ModuleResource{
			Module:       row[1],
			ResourceType: row[0],
			Quantity:     row[2],
		})
	}

	return resources
}

// transform
// It takes an array of structured ModuleResource and transform it into an array of structured Modules to write the yaml file
func transform(resources []ModuleResource) []Modules {
	grouped := make(map[string][]string)

	for _, r := range resources {
		grouped[r.Module] = append(grouped[r.Module], r.ResourceType)
	}

	var yamlResources []Modules
	for moduleName, resourceTypes := range grouped {
		yamlResources = append(yamlResources, Modules{
			Name:      moduleName,
			Resources: resourceTypes,
		})
	}

	return yamlResources
}

// WriteYaml
// It takes an filename and the resources and transform them to module syntax to write the Yaml file
func WriteYaml(filename string, resources []ModuleResource) {
	yamlResources := transform(resources)

	data, err := yaml.Marshal(map[string][]Modules{"modules": yamlResources})
	if err != nil {
		log.Fatalf("Error writing YAML: %v", err)
	}
	configData, err := yaml.Marshal(map[string][]string{
		"config": {"one", "two"},
	})
	data = append(data, configData...)
	ioutil.WriteFile(filename, data, 0644)
	fmt.Println("YAML written to tfmodule.yaml")
}

// WriteToFile
// It takes the content, the filename path and a success string and writes the content to the file and prints the success string
func WriteToFile(content string, path string, success string) {
	// Open file with flag to create if it doesn't exist, write-only mode, and truncate if it exists
	file, err := os.OpenFile(path, os.O_WRONLY|os.O_CREATE|os.O_TRUNC, 0644)
	if err != nil {
		log.Fatalf("Failed opening %s: %s", path, err)
		return
	}
	defer file.Close()

	_, err = file.WriteString(content)
	if err != nil {
		log.Fatalf("Failed writing to %s: %s", path, err)
		return
	}

	fmt.Println(success)
}

// WriteToCsv
// it takes the structure []CsvResources and writes it into the csv filename provided
func WriteToCsv(resources []CsvResources, filename string) {
	file, err := os.Create(filename)
	if err != nil {
		log.Fatalf("Could not create file: %v", err)
	}
	defer file.Close()

	writer := csv.NewWriter(file)
	defer writer.Flush()

	// Write the header
	err = writer.Write([]string{"Resource", "Module", "Quantity"})
	if err != nil {
		log.Fatalf("Could not write to CSV: %v", err)
	}

	// Write the data
	for _, resource := range resources {
		err := writer.Write([]string{resource.Resource, resource.Module,
			fmt.Sprintf("%d", resource.Quantity)})
		if err != nil {
			log.Fatalf("Could not write to CSV: %v", err)
		}
	}
	fmt.Println("Written succefully into the file: " + filename)
}

func ReadMultipleResourceGroups(src string, newFolder string) (string, string) {
	json := ""
	terra := ""
	firstIteration := true

	if _, err := os.Stat(newFolder); !os.IsNotExist(err) {
		// directory exists
		err = os.RemoveAll(newFolder)
		if err != nil {
			fmt.Println("Failed to delete folder:", err)
		} else {
			fmt.Println("Folder deleted successfully.")
		}
	}

	err := filepath.Walk(src, func(path string, info os.FileInfo, err error) error {
		if err != nil {
			return err
		}

		if info.IsDir() && path != src {
			json, terra = processDirectory(path, json, terra)
			if firstIteration {
				if err := os.Mkdir(newFolder, 0755); err != nil {
					fmt.Println("Error:", err)
				}

				// Copy provider.tf and terraform.tf files to the new folder on the first iteration
				if err := copyFile(filepath.Join(path, "provider.tf"), newFolder+"/provider.tf"); err != nil {
					fmt.Printf("Failed to copy provider.tf from %s to %s: %s\n", path, newFolder, err)
				}
				if err := copyFile(filepath.Join(path, "terraform.tf"), newFolder+"/terraform.tf"); err != nil {
					fmt.Printf("Failed to copy terraform.tf from %s to %s: %s\n", path, newFolder, err)
				}
				firstIteration = false
			}
			return filepath.SkipDir // skip traversing the inside of this directory further as we process it at once
		}

		return nil
	})

	if err != nil {
		fmt.Println("Error processing directories:", err)
	}
	json = json[:len(json)-2]
	json = "{\n" + json + "\n}"
	return json, terra
}

func processDirectory(dirPath string, json string, terra string) (string, string) {
	// Specify the JSON and .tf file names if they are fixed or modify logic to detect them
	jsonFilePath := filepath.Join(dirPath, "aztfexportResourceMapping.json")
	tfFilePath := filepath.Join(dirPath, "main.tf")

	// Read JSON file content
	jsonContent, err := ioutil.ReadFile(jsonFilePath)
	if err != nil {
		fmt.Printf("Failed reading %s: %s\n", jsonFilePath, err)
		return json, terra
	}

	// Read .tf file content
	tfContent, err := ioutil.ReadFile(tfFilePath)
	if err != nil {
		fmt.Printf("Failed reading %s: %s\n", tfFilePath, err)
		return json, terra
	}

	json_to_add := string(jsonContent)

	json_to_add = json_to_add[2:len(json_to_add)-2] + ",\n"
	json += json_to_add
	terra += string(tfContent)
	return json, terra
}

func copyFile(src, dest string) error {
	input, err := ioutil.ReadFile(src)
	if err != nil {
		return err
	}

	err = ioutil.WriteFile(dest, input, 0644)
	if err != nil {
		return err
	}
	return nil
}
